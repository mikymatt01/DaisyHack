{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0318b018",
   "metadata": {},
   "source": [
    "# Review of Pathfinding Algorithms in the Minihack Environment\n",
    "### DaisyHack Team for the Artificial Intelligence Fundamental Course, 2023/2024\n",
    "Cosimo Botticelli, Maria Colella, Michele Mattiello, Nazifa Mosharrat, Roberto Della Rocca\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f027bf0e",
   "metadata": {},
   "source": [
    "### Setting up the environment\n",
    "Assuming we are in a proper virtual environment, we can setup the environment and import the adequate packages using the following block of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba7fc9-72b7-4b42-b347-0d82e6065367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import minihack\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as display\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from collections import deque\n",
    "from queue import PriorityQueue\n",
    "from utilsMinihackSearch import *\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f147c6d-8ac1-48a7-8008-8aae8f796240",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hill Climbing Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ea4610",
   "metadata": {},
   "source": [
    "For our first search algorithm, we expect a simple and greedy behaviour that can quickly cover large distances but gets stuck at the fist local minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eebe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform hill climbing algorithm to find a path from start to target\n",
    "def hill_climb(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int], h: callable) -> List[Tuple[int, int]]:\n",
    "    # Initialize the current state with the start position\n",
    "    current = {'state': start}\n",
    "    # Initialize the parent dictionary to track paths\n",
    "    parent = {start: None}  \n",
    "    # Continue the loop until a solution is found or an appropriate condition is met\n",
    "    while True:\n",
    "        # Find the highest valued successor based on the heuristic\n",
    "        neighbor = highest_valued_successors(current, game_map, target, h)\n",
    "        # Check if the heuristic value of the neighbor is less than or equal to the current state\n",
    "        if h(neighbor['state'], target) >= h(current['state'], target):\n",
    "            # If true, construct and return the path\n",
    "            path = build_path_HillClimb(parent, start, target)\n",
    "            return path\n",
    "        \n",
    "        # Update the parent dictionary with the current and neighbor states\n",
    "        parent[neighbor['state']] = current['state']\n",
    "        # Move to the neighbor state for the next iteration\n",
    "        current = neighbor\n",
    "        \n",
    "        # Debugging statements\n",
    "        # print(\"Parent dictionary:\", parent)  \n",
    "        # print(\"Target:\", target)\n",
    "        # print(\"Current state:\", current['state'])\n",
    "\n",
    "# Function to build the path from the parent dictionary\n",
    "def build_path_HillClimb(parent: dict, start: Tuple[int, int], target: Tuple[int, int]) -> List[Tuple[int, int]]:\n",
    "    path = []\n",
    "    current = target\n",
    "    \n",
    "    # Continue until reaching the start or a dead end\n",
    "    while current is not None and current != start:\n",
    "        # Append the current state to the path\n",
    "        path.append(current)\n",
    "        # Check if the current state is not in the parent dictionary\n",
    "        if current not in parent:\n",
    "            print(f\"Target {target} not reachable from start {start}.\")\n",
    "            return None\n",
    "        # Move to the parent state for backtracking\n",
    "        current = parent[current]\n",
    "    \n",
    "    # Add the starting point to the path and reverse the order\n",
    "    path.append(start)\n",
    "    path.reverse()\n",
    "    \n",
    "    return path\n",
    "\n",
    "# Function to find the highest valued successor based on the heuristic\n",
    "def highest_valued_successors(node, game_map, target, h):\n",
    "    # Get valid moves (successors) from the current state\n",
    "    successors = get_valid_moves(game_map, node['state'])\n",
    "    # Sort successors based on the heuristic value in descending order\n",
    "    successors.sort(key=lambda x: h(x, target), reverse=True)\n",
    "    successors.reverse()\n",
    "    # Return the highest valued successor\n",
    "    return {'state': successors[0]}\n",
    "\n",
    "env = gym.make(\n",
    "    \"MiniHack-Navigation-Custom-v0\",\n",
    "    observation_keys=(\"chars\", \"pixel\"),\n",
    "    des_file = \"mazes/empty.des\",\n",
    ")\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75186a7d",
   "metadata": {},
   "source": [
    "#### Empty map\n",
    "A first simple map is useful to show how the algorithm behaves in a very smooth solution space, with no local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6417673",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(state['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5830e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = state['chars']\n",
    "game = state['pixel'][70:300, 500:730]\n",
    "start = get_player_location(game_map)\n",
    "target = get_target_location(game_map)\n",
    "print(\"Agent position:\", start)\n",
    "print(\"Target position:\", target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8163d337",
   "metadata": {},
   "source": [
    "The path to the exit is computed and stored, if it does exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a5b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = hill_climb(game_map, start, target, manhattan_distance)\n",
    "actions = actions_from_path(start, path[1:])\n",
    "image = plt.imshow(game)\n",
    "for action in actions:\n",
    "    s, _, _, _ = env.step(action)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    image.set_data(s['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc6723b",
   "metadata": {},
   "source": [
    "#### Map with a single local minima\n",
    "This map shows the limits of a greedy algorithm; it gets stuck on the very first local minima despite there being a valid solution (multiple solutions, in fact)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76cd46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"MiniHack-Navigation-Custom-v0\",\n",
    "    observation_keys=(\"chars\", \"pixel\"),\n",
    "    des_file = \"mazes/one_local_minimum.des\",\n",
    ")\n",
    "state = env.reset()\n",
    "plt.imshow(state['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3fe607",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = state['chars']\n",
    "game = state['pixel'][70:300, 500:730]\n",
    "start = get_player_location(game_map)\n",
    "target = get_target_location(game_map)\n",
    "print(\"Agent position:\", start)\n",
    "print(\"Target position:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a9f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = hill_climb(game_map, start, target, manhattan_distance)\n",
    "if path is not None:\n",
    "    actions = actions_from_path(start, path[1:])\n",
    "    image = plt.imshow(game)\n",
    "    for action in actions:\n",
    "        s, _, _, _ = env.step(action)\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        image.set_data(s['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5f8ac3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hill Climbing Search with Backtracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b01f18",
   "metadata": {},
   "source": [
    "A variation of our first algorithm goes to show how a little addition can go a long way.\n",
    "\n",
    "We add backtracking in order to get out of local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be416746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_path_HillClimb(parent: dict, start: Tuple[int, int], target: Tuple[int, int]) -> List[Tuple[int, int]]:\n",
    "    path = []\n",
    "    current = target\n",
    "\n",
    "    while current is not None and current != start:\n",
    "        path.append(current)\n",
    "        current = parent[current]\n",
    "\n",
    "    path.append(start)  # Add the starting point to the path\n",
    "    path.reverse()\n",
    "\n",
    "    return path\n",
    "\n",
    "def hill_climb(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int], h: callable) -> List[Tuple[int, int]]:\n",
    "    # initialize open and close list\n",
    "    open_list = [start]\n",
    "    close_list = []\n",
    "    parent = {start: None}\n",
    "\n",
    "    while open_list:\n",
    "        # getting the current node\n",
    "        current = open_list.pop()\n",
    "        # adding the node to the close list\n",
    "        close_list.append(current)\n",
    "\n",
    "        if current == target:\n",
    "            path = build_path_HillClimb(parent, start,target)\n",
    "            return path\n",
    "\n",
    "        for neighbor in get_valid_moves(game_map, current):\n",
    "            # check if neighbor in close list, if so continue\n",
    "            if neighbor in close_list:\n",
    "                continue\n",
    "\n",
    "            # compute neighbor h value\n",
    "            neighbor_h = h(neighbor, target)\n",
    "            parent[neighbor] = current\n",
    "            # if neighbor not in open list, adding it\n",
    "            if neighbor not in open_list:\n",
    "                open_list.append(neighbor)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3256293b",
   "metadata": {},
   "source": [
    "####  Map with a single local minimum\n",
    "This map has a single local minimum; with a little backtracking we can handle this easily and in fact the character goes around the critical area and gets to the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b899217",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"MiniHack-Navigation-Custom-v0\",\n",
    "    observation_keys=(\"chars\", \"pixel\"),\n",
    "    des_file = \"mazes/one_local_minimum.des\",\n",
    ")\n",
    "state = env.reset()\n",
    "\n",
    "plt.imshow(state['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a20fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = state['chars']\n",
    "game = state['pixel'][70:300, 500:730]\n",
    "\n",
    "start = get_player_location(game_map)\n",
    "target = get_target_location(game_map)\n",
    "print(\"Agent position:\", start)\n",
    "print(\"Target position:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfeb6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    path = hill_climb(game_map, start, target, manhattan_distance)\n",
    "    if path is not None:\n",
    "        print(\"Path found!\")\n",
    "    else:\n",
    "        print(\"Path not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1b99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = actions_from_path(start, path[1:])\n",
    "image = plt.imshow(game)\n",
    "for action in actions:\n",
    "    s, _, _, _ = env.step(action)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    image.set_data(s['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da5ffa7",
   "metadata": {},
   "source": [
    "####  A map with multiple local minima\n",
    "\n",
    "This map with several local minima tests the limit of this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6350870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"MiniHack-Navigation-Custom-v0\",\n",
    "    observation_keys=(\"chars\", \"pixel\"),\n",
    "    des_file = \"mazes/many_local_minima.des\",\n",
    ")\n",
    "state = env.reset()\n",
    "\n",
    "plt.imshow(state['pixel'][100:285, 500:765])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8379618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = state['chars']\n",
    "game = state['pixel'][100:285, 500:765]\n",
    "\n",
    "start = get_player_location(game_map)\n",
    "target = get_target_location(game_map)\n",
    "print(\"Agent position:\", start)\n",
    "print(\"Target position:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872cbc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    path = hill_climb(game_map, start, target, manhattan_distance)\n",
    "    if path is not None:\n",
    "        print(\"Path found!\")\n",
    "    else:\n",
    "        print(\"Path not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce7143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = actions_from_path(start, path[1:])\n",
    "image = plt.imshow(game)\n",
    "for action in actions:\n",
    "    s, _, _, _ = env.step(action)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    image.set_data(s['pixel'][100:285, 500:765])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff52dd",
   "metadata": {},
   "source": [
    "^ this should fail but doesn't"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3634038d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Local Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d988460a",
   "metadata": {},
   "source": [
    "With this algorithm we trade off some memory for better exploration capabilities.\n",
    "\n",
    "The *k* best states are kept in memory and exploder when the current path being explored fails to reach the goal.\n",
    "\n",
    "This algorithm could be complete for maps of any size with the allocation of infinite memory, in theory.\n",
    "\n",
    "In practice, it's up to us to choose the best amount of memory to allocate.\n",
    "\n",
    "##### Stochasticity\n",
    "\n",
    "Furthermore, the direction chosem by this algorithm is sometimes left up to chance. This lets us explore more thoroughly the solution space, but one execution of the algorithm is not enough to determine its efficiency.\n",
    "\n",
    "Thus, in the next few examples, we will run the algorithm 1000 times for each map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b37415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "def initialize_states(game_map: np.ndarray, start: Tuple[int, int], k: int):\n",
    "\n",
    "    init_states = [list(random.choice(get_valid_moves(game_map, start))) for _ in range(k)]\n",
    "    \n",
    "    current_states = []\n",
    "    for state in init_states:\n",
    "        current_states.append({\n",
    "            'current': tuple(state),\n",
    "            'explored_nodes': [tuple(state)],\n",
    "            'path': [tuple(state)]\n",
    "        })\n",
    "\n",
    "    return current_states\n",
    "\n",
    "def get_successors_from_states(game_map: np.ndarray, states: list):\n",
    "\n",
    "    state_neighbors = []\n",
    "\n",
    "    for state in states:\n",
    "        neighbors = get_valid_moves(game_map, state['current'])\n",
    "        state_neighbors.append({\n",
    "            'path': state['path'],\n",
    "            'explored_nodes': state['explored_nodes'],\n",
    "            'possible_moves': neighbors\n",
    "        })\n",
    "        \n",
    "\n",
    "    return state_neighbors\n",
    "\n",
    "def get_heuristic_scores(heuristic: callable, neighbors: list):\n",
    "\n",
    "    scored_moves = []\n",
    "\n",
    "    for state in neighbors:\n",
    "        for move in state['possible_moves']:\n",
    "            score_target = heuristic(move, target)\n",
    "            score_start = heuristic(start, move)\n",
    "            scored_moves.append({\n",
    "                'path': state['path'],\n",
    "                'explored_nodes': state['explored_nodes'],\n",
    "                'current': move,\n",
    "                'distance_from_target': score_target,\n",
    "                'distance_from_start': score_start\n",
    "            })\n",
    "    \n",
    "    return scored_moves\n",
    "\n",
    "def assign_probabilities(sorted_array):\n",
    "    n = len(sorted_array)\n",
    "    probabilities = [1 / (i + 1) for i in range(n)]\n",
    "    \n",
    "    # give the same probability if two elements has the same distance\n",
    "    for i in range(1, n):\n",
    "        if sorted_array[i] == sorted_array[i - 1]:\n",
    "            probabilities[i] = probabilities[i - 1]\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "def get_next_states(scored_successors: list, k: int, stocastic: bool):\n",
    "\n",
    "    scored_successors_from_target = sorted(scored_successors, key = lambda x: x['distance_from_target'])\n",
    "    scored_successors_from_start = sorted(scored_successors, key = lambda x: x['distance_from_start'], reverse=True)\n",
    "    scored_successors = None\n",
    "\n",
    "    if scored_successors_from_start[0]['distance_from_start'] - 15 < scored_successors_from_target[0]['distance_from_target'] :\n",
    "        scored_successors = scored_successors_from_start\n",
    "    else:\n",
    "        scored_successors = scored_successors_from_target\n",
    "\n",
    "    # scored_successors = scored_successors_from_start\n",
    "\n",
    "    top = []\n",
    "\n",
    "    if stocastic:\n",
    "        cont = 0\n",
    "        while cont < k:\n",
    "            # top.append(scored_successors[random.randrange(0, len(scored_successors))])\n",
    "            probability_array = assign_probabilities(scored_successors)\n",
    "            choice = random.choices(scored_successors, probability_array)[0]\n",
    "            if choice not in top:\n",
    "                top.append(choice)\n",
    "                cont += 1\n",
    "    else:\n",
    "        cont = 0\n",
    "        for succ in scored_successors:\n",
    "            if cont < k:\n",
    "                if succ['current'] not in succ['explored_nodes']:\n",
    "                    succ['explored_nodes'] = succ['explored_nodes'] + [succ['current']]\n",
    "                    top.append(succ)\n",
    "                    cont += 1\n",
    "\n",
    "                \n",
    "    \n",
    "    next_states = list()\n",
    "    \n",
    "    for s in top:\n",
    "        next_states.append({\n",
    "            'current': s['current'],\n",
    "            'explored_nodes': s['explored_nodes'],\n",
    "            'path': s['path'] + [s['current']]\n",
    "        })\n",
    "    \n",
    "    return next_states\n",
    "\n",
    "\n",
    "def local_beam_search(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int], heuristic: callable, k: int = 3, max_iter: int = 100, stocastic: bool = False):\n",
    "\n",
    "    current_states = initialize_states(game_map, start, k)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "\n",
    "        state_neighbors = get_successors_from_states(game_map, current_states)\n",
    "\n",
    "        if len(current_states) == 0 or i == max_iter - 1:\n",
    "            path = [start] + backup_states[0]['path'] + [move]\n",
    "            return None\n",
    "        \n",
    "        # check if a possible move is the target\n",
    "        for state in state_neighbors:\n",
    "            for move in state['possible_moves']:\n",
    "                if move == target:\n",
    "                   path = [start] + state['path'] + [move]\n",
    "                   return path\n",
    "\n",
    "        scored_successors = get_heuristic_scores(heuristic, state_neighbors)\n",
    "        backup_states = current_states\n",
    "        current_states = get_next_states(scored_successors, k, stocastic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491dbeef",
   "metadata": {},
   "source": [
    "#### Map with two local minima\n",
    "A map with two local minima, easy to manage for a beam search algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3500be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"MiniHack-Navigation-Custom-v0\",\n",
    "    observation_keys=(\"chars\", \"pixel\"),\n",
    "    des_file = \"mazes/two_local_minima.des\",\n",
    ")\n",
    "state = env.reset()\n",
    "\n",
    "plt.imshow(state['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef961c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = state['chars']\n",
    "game = state['pixel'][70:300, 500:730]\n",
    "start = get_player_location(game_map)\n",
    "target = get_target_location(game_map)\n",
    "print(\"Agent position:\", start)\n",
    "print(\"Target position:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ccf5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "founded = 0\n",
    "finalPath = None\n",
    "for i in range(1000):\n",
    "    path = local_beam_search(game_map, get_player_location(game_map), get_target_location(game_map), manhattan_distance, stocastic=False, max_iter=10000)\n",
    "    if path:\n",
    "        founded += 1\n",
    "        finalPath = path\n",
    "\n",
    "print(f\"{founded}/1000 correct paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af22c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = actions_from_path(start, path[1:])\n",
    "image = plt.imshow(game)\n",
    "for action in actions:\n",
    "    s, _, _, _ = env.step(action)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    image.set_data(s['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d625f5f",
   "metadata": {},
   "source": [
    "#### Medium difficulty maze\n",
    "A maze with multiple local minima, but still manageable for the Local Beam Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef52c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"MiniHack-Navigation-Custom-v0\",\n",
    "    observation_keys=(\"chars\", \"pixel\"),\n",
    "    des_file = \"mazes/medium_diff_maze.des\",\n",
    ")\n",
    "state = env.reset()\n",
    "\n",
    "plt.imshow(state['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ef07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = state['chars']\n",
    "game = state['pixel'][70:300, 500:730]\n",
    "start = get_player_location(game_map)\n",
    "target = get_target_location(game_map)\n",
    "print(\"Agent position:\", start)\n",
    "print(\"Target position:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ff3b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_paths = 0\n",
    "finalPath = None\n",
    "for i in range(1000):\n",
    "    path = local_beam_search(game_map, get_player_location(game_map), get_target_location(game_map), manhattan_distance, stocastic=False, max_iter=10000)\n",
    "    if path is not None:\n",
    "        correct_paths += 1\n",
    "        finalPath = path\n",
    "\n",
    "print(f\"{correct_paths}/1000 correct paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = actions_from_path(start, finalPath[1:])\n",
    "image = plt.imshow(game)\n",
    "for action in actions:\n",
    "    s, _, _, _ = env.step(action)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    image.set_data(s['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c091b",
   "metadata": {},
   "source": [
    "#### Failure state map\n",
    "This is an example of a maze that can't be solved by the algorithm.\n",
    "\n",
    "We can see the player trying to get far away from the starting point and then getting stuck irreversably in a local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e8924",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"MiniHack-Navigation-Custom-v0\",\n",
    "    observation_keys=(\"chars\", \"pixel\"),\n",
    "    des_file = \"mazes/hard_maze.des\",\n",
    ")\n",
    "state = env.reset()\n",
    "\n",
    "plt.imshow(state['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d6e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = state['chars']\n",
    "game = state['pixel'][70:300, 500:730]\n",
    "start = get_player_location(game_map)\n",
    "target = get_target_location(game_map)\n",
    "print(\"Agent position:\", start)\n",
    "print(\"Target position:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f28f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_paths = 0\n",
    "finalPath = None\n",
    "for i in range(1000):\n",
    "    path = local_beam_search(game_map, get_player_location(game_map), get_target_location(game_map), manhattan_distance, stocastic=False, max_iter=10000)\n",
    "    if path is not None:\n",
    "        correct_paths += 1\n",
    "        finalPath = path\n",
    "\n",
    "if correct_paths == 0:\n",
    "    print(\"No path to the exit has been found.\")\n",
    "else:\n",
    "    print(f\"{correct_paths}/1000 correct paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777c5d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ab83cd",
   "metadata": {},
   "source": [
    "A custom genetic algorithm that can build path through evolutive concepts such as selection of best specimens in order to get better and better solutions, and mutation in order to explore good but unpromising paths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3805c6f5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Simulated Annealing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839a9ddf",
   "metadata": {},
   "source": [
    "With this algorithm we exploit a lot of randomness during the first steps in order to explore the solution space thoroughly, and to get out of local optima.\n",
    "\n",
    "Moving forward, the temperature lowers, and the chanche of taking sub-optimal steps lowers with it.\n",
    "\n",
    "The algorithm eventually converges to always chosing the optimal step, akin to an Hill Climbing search, and has a maximum number of steps as termination condition, if it still can't find the exit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec130912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_schedule(t: int):\n",
    "    \"\"\"One possible schedule function for simulated annealing\"\"\"\n",
    "    return t * 0.95\n",
    "\n",
    "def assign_probabilities(sorted_array, deltas, t):\n",
    "    n = len(sorted_array)\n",
    "    if t < 0.01:\n",
    "        probabilities = [1] + [0] * (n - 1)\n",
    "    else:\n",
    "        probabilities = [math.exp(-deltas[i] / t) for i in range(n)]\n",
    "    return probabilities\n",
    "\n",
    "def ordered_successors(node, game_map, target, h):\n",
    "    successors = get_valid_moves(game_map, node['state'])\n",
    "    successors.sort(key=lambda x: h(x, target), reverse=True)\n",
    "    successors.reverse()\n",
    "    return successors\n",
    "\n",
    "def calcolo_delta(neighbors, current, h, target):\n",
    "    deltas = []\n",
    "    n = len(neighbors)\n",
    "    current_hValue = h(current['state'], target)\n",
    "    for i in range(n):\n",
    "        x = h(neighbors[i], target)\n",
    "        deltas.append(x - current_hValue)\n",
    "    return deltas\n",
    "\n",
    "def simulated_annealing(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int], h: callable, T: int, annealing: float) -> List[Tuple[int, int]]:\n",
    "    path = []\n",
    "    current = {'state': start}\n",
    "    startt = {'state': start}\n",
    "    path.append(start)\n",
    "    while True: \n",
    "        if T > 0:\n",
    "            T = exp_schedule(T)\n",
    "        neighbors = ordered_successors(current, game_map, target, h)\n",
    "        deltas = calcolo_delta(neighbors, startt, h, target)\n",
    "        probabilities = assign_probabilities(neighbors, deltas, T)\n",
    "        # print(f\"deltas: {deltas},   prob: {probabilities}, T: {T}\")\n",
    "        choice = random.choices(neighbors, probabilities)[0]\n",
    "        path.append(choice)\n",
    "        current = {'state': choice}\n",
    "        # print(f\"choice: {current}\")\n",
    "        if current['state'] == target:\n",
    "            return path, True\n",
    "        if len(path) == 100:\n",
    "            return path, False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5de0a2f",
   "metadata": {},
   "source": [
    "#### Empty map\n",
    "Such a map is easily solvable by a simulated annealing search, since the algorithm eventually behaves like a hill climbing search, which as we have already seen, can solve an empty map quite easily.\n",
    "\n",
    "It's still useful to observe this case since it shows very well how the algorithm behaves quite chaotically in the beginning and then starts to converge towards a greedy behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1a6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"MiniHack-Navigation-Custom-v0\",\n",
    "    observation_keys=(\"chars\", \"pixel\"),\n",
    "    des_file = \"mazes/empty.des\",\n",
    ")\n",
    "state = env.reset()\n",
    "\n",
    "plt.imshow(state['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c81b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = state['chars']\n",
    "game = state['pixel'][70:300, 500:730]\n",
    "start = get_player_location(game_map)\n",
    "target = get_target_location(game_map)\n",
    "print(\"Agent position:\", start)\n",
    "print(\"Target position:\", target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ed2e4",
   "metadata": {},
   "source": [
    "We call the algorithm with an `annealing` value of 0.92, meaning the temperature will drop by 8% of its current value of each step. This is quite a big drop in temperature, but fitting to the map at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd73307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "found = 0\n",
    "finalPath = None\n",
    "numIter = 1\n",
    "for i in range(numIter):\n",
    "    path, isPathFound = simulated_annealing(game_map, start, target, manhattan_distance, 100, annealing = 0.92)\n",
    "    if isPathFound:\n",
    "        found += 1\n",
    "        finalPath = path\n",
    "\n",
    "print(f\"{found}/{numIter} correct paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7acedf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"st: {start}, pat: {finalPath}\")\n",
    "actions = actions_from_path(start, finalPath[1:])\n",
    "image = plt.imshow(game)\n",
    "for action in actions:\n",
    "    s, _, _, _ = env.step(action)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    image.set_data(s['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3ca79a",
   "metadata": {},
   "source": [
    "#### Hard maze\n",
    "This is a maze that can't be solved 100% of the time, so we execute the algorithm multiple times and with different values for `annealing`; in particular, the algorithm is ran 10 times for each value of `annealing` ranging from 0.899 to 0.999, with an increment step of 0.001, for a total of 1000 executions.\n",
    "\n",
    "The solution with the smallest amount of steps is then memorized and shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0541230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"MiniHack-Navigation-Custom-v0\",\n",
    "    observation_keys=(\"chars\", \"pixel\"),\n",
    "    des_file = \"mazes/hard_maze.des\",\n",
    ")\n",
    "state = env.reset()\n",
    "\n",
    "plt.imshow(state['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece83768",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = state['chars']\n",
    "game = state['pixel'][70:300, 500:730]\n",
    "start = get_player_location(game_map)\n",
    "target = get_target_location(game_map)\n",
    "print(\"Agent position:\", start)\n",
    "print(\"Target position:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c64b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "found = 0\n",
    "finalPath = None\n",
    "numIter = 1000\n",
    "dynamicAnnealing = 0.899\n",
    "for i in range(100):\n",
    "    dynamicAnnealing = dynamicAnnealing + 0.001\n",
    "    for j in range(10):\n",
    "        path, isPathFound = simulated_annealing(game_map, start, target, manhattan_distance, 100, annealing = dynamicAnnealing)\n",
    "        if isPathFound:\n",
    "            found += 1\n",
    "            if(found == 1):\n",
    "                finalPath = path\n",
    "            if len(path) < len(finalPath):\n",
    "                finalPath = path\n",
    "\n",
    "print(f\"{found}/{numIter} correct paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde1fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"st: {start}, pat: {finalPath}\")\n",
    "actions = actions_from_path(start, finalPath[1:])\n",
    "image = plt.imshow(game)\n",
    "for action in actions:\n",
    "    s, _, _, _ = env.step(action)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    image.set_data(s['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c72900",
   "metadata": {},
   "source": [
    "#### Maze which is pathologically full of local minima\n",
    "This maze is comprised of a lot of local minima. Even then, we aim to show that simulated annealing can squeeze its way through the correct path, diven enough iterations and variations in the `annealing` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acda290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"MiniHack-Navigation-Custom-v0\",\n",
    "    observation_keys=(\"chars\", \"pixel\"),\n",
    "    des_file = \"mazes/many_local_minima.des\",\n",
    ")\n",
    "state = env.reset()\n",
    "\n",
    "plt.imshow(state['pixel'][100:265, 500:730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ef6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = state['chars']\n",
    "game = state['pixel'][100:265, 500:730]\n",
    "start = get_player_location(game_map)\n",
    "target = get_target_location(game_map)\n",
    "print(\"Agent position:\", start)\n",
    "print(\"Target position:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340e3033",
   "metadata": {},
   "outputs": [],
   "source": [
    "found = 0\n",
    "finalPath = None\n",
    "numIter = 2500\n",
    "dynamicAnnealing = 0.899\n",
    "for i in range(100):\n",
    "    dynamicAnnealing = dynamicAnnealing + 0.001\n",
    "    for j in range(25):\n",
    "        path, isPathFound = simulated_annealing(game_map, start, target, manhattan_distance, 100, annealing = dynamicAnnealing)\n",
    "        if isPathFound:\n",
    "            found += 1\n",
    "            if(found == 1):\n",
    "                finalPath = path\n",
    "            if len(path) < len(finalPath):\n",
    "                finalPath = path\n",
    "\n",
    "print(f\"{found}/{numIter} correct paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de07c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"st: {start}, pat: {finalPath}\")\n",
    "actions = actions_from_path(start, finalPath[1:])\n",
    "image = plt.imshow(game)\n",
    "for action in actions:\n",
    "    s, _, _, _ = env.step(action)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    image.set_data(s['pixel'][100:265, 500:730])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
