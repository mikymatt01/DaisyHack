{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0318b018",
   "metadata": {},
   "source": [
    "# Review of Pathfinding Algorithms in the Minihack Environment\n",
    "### DaisyHack Team for the Artificial Intelligence Fundamental Course, 2023/2024\n",
    "Cosimo Botticelli, Maria Colella, Michele Mattiello, Nazifa Mosharrat, Roberto Della Rocca\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f027bf0e",
   "metadata": {},
   "source": [
    "### Setting up the environment\n",
    "Assuming we are in a proper virtual environment, we can setup the environment and import the adequate packages using the following block of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba7fc9-72b7-4b42-b347-0d82e6065367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import minihack\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as display\n",
    "\n",
    "from collections import deque\n",
    "from queue import PriorityQueue\n",
    "from utilsMinihackSearch import *\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f147c6d-8ac1-48a7-8008-8aae8f796240",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hill Climbing Search\n",
    "\n",
    "For our first search algorithm, we expect a simple and greedy behaviour that can quickly cover large distances but gets stuck at the fist local minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eebe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform hill climbing algorithm to find a path from start to target\n",
    "def hill_climb(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int], h: callable) -> List[Tuple[int, int]]:\n",
    "    # Initialize the current state with the start position\n",
    "    current = {'state': start}\n",
    "    # Initialize the parent dictionary to track paths\n",
    "    parent = {start: None}  \n",
    "    # Continue the loop until a solution is found or an appropriate condition is met\n",
    "    while True:\n",
    "        # Find the highest valued successor based on the heuristic\n",
    "        neighbor = highest_valued_successors(current, game_map, target, h)\n",
    "        # Check if the heuristic value of the neighbor is less than or equal to the current state\n",
    "        if h(neighbor['state'], target) >= h(current['state'], target):\n",
    "            # If true, construct and return the path\n",
    "            path = build_path_HillClimb(parent, start, target)\n",
    "            return path\n",
    "        \n",
    "        # Update the parent dictionary with the current and neighbor states\n",
    "        parent[neighbor['state']] = current['state']\n",
    "        # Move to the neighbor state for the next iteration\n",
    "        current = neighbor\n",
    "        \n",
    "        # Debugging statements\n",
    "        print(\"Parent dictionary:\", parent)  \n",
    "        print(\"Target:\", target)\n",
    "        print(\"Current state:\", current['state'])\n",
    "\n",
    "# Function to build the path from the parent dictionary\n",
    "def build_path_HillClimb(parent: dict, start: Tuple[int, int], target: Tuple[int, int]) -> List[Tuple[int, int]]:\n",
    "    path = []\n",
    "    current = target\n",
    "    \n",
    "    # Continue until reaching the start or a dead end\n",
    "    while current is not None and current != start:\n",
    "        # Append the current state to the path\n",
    "        path.append(current)\n",
    "        # Check if the current state is not in the parent dictionary\n",
    "        if current not in parent:\n",
    "            print(f\"Target {target} not reachable from start {start}.\")\n",
    "            return None\n",
    "        # Move to the parent state for backtracking\n",
    "        current = parent[current]\n",
    "    \n",
    "    # Add the starting point to the path and reverse the order\n",
    "    path.append(start)\n",
    "    path.reverse()\n",
    "    \n",
    "    return path\n",
    "\n",
    "# Function to find the highest valued successor based on the heuristic\n",
    "def highest_valued_successors(node, game_map, target, h):\n",
    "    # Get valid moves (successors) from the current state\n",
    "    successors = get_valid_moves(game_map, node['state'])\n",
    "    # Sort successors based on the heuristic value in descending order\n",
    "    successors.sort(key=lambda x: h(x, target), reverse=True)\n",
    "    successors.reverse()\n",
    "    # Return the highest valued successor\n",
    "    return {'state': successors[0]}\n",
    "\n",
    "env = gym.make(\n",
    "    \"MiniHack-Navigation-Custom-v0\",\n",
    "    observation_keys=(\"chars\", \"pixel\"),\n",
    "    des_file = \"mazes/empty.des\",\n",
    ")\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75186a7d",
   "metadata": {},
   "source": [
    "#### Empty map\n",
    "A first simple map is useful to show how the algorithm behaves in a very smooth solution space, with no local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6417673",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(state['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5830e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = state['chars']\n",
    "game = state['pixel'][70:300, 500:730]\n",
    "start = get_player_location(game_map)\n",
    "target = get_target_location(game_map)\n",
    "print(\"Agent position:\", start)\n",
    "print(\"Target position:\", target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8163d337",
   "metadata": {},
   "source": [
    "The path to the exit is computed and stored, if it does exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e0e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = hill_climb(game_map, start, target, manhattan_distance)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a5b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = actions_from_path(start, path[1:])\n",
    "image = plt.imshow(game)\n",
    "for action in actions:\n",
    "    s, _, _, _ = env.step(action)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    image.set_data(s['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dc0d3b",
   "metadata": {},
   "source": [
    "*here should go the other examples but the algorithm has to be fixed first*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5f8ac3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hill Climbing Search with Backtracking\n",
    "\n",
    "A variation of our first algorithm goes to show how a little addition can go a long way.\n",
    "\n",
    "We add backtracking in order to get out of local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be416746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_path_HillClimb(parent: dict, start: Tuple[int, int], target: Tuple[int, int]) -> List[Tuple[int, int]]:\n",
    "    path = []\n",
    "    current = target\n",
    "\n",
    "    while current is not None and current != start:\n",
    "        path.append(current)\n",
    "        current = parent[current]\n",
    "\n",
    "    path.append(start)  # Add the starting point to the path\n",
    "    path.reverse()\n",
    "\n",
    "    return path\n",
    "\n",
    "def hill_climb(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int], h: callable) -> List[Tuple[int, int]]:\n",
    "    # initialize open and close list\n",
    "    open_list = [start]\n",
    "    close_list = []\n",
    "    parent = {start: None}\n",
    "\n",
    "    while open_list:\n",
    "        # getting the current node\n",
    "        current = open_list.pop()\n",
    "        # adding the node to the close list\n",
    "        close_list.append(current)\n",
    "\n",
    "        if current == target:\n",
    "            path = build_path_HillClimb(parent, start,target)\n",
    "            return path\n",
    "\n",
    "        for neighbor in get_valid_moves(game_map, current):\n",
    "            # check if neighbor in close list, if so continue\n",
    "            if neighbor in close_list:\n",
    "                continue\n",
    "\n",
    "            # compute neighbor h value\n",
    "            neighbor_h = h(neighbor, target)\n",
    "            parent[neighbor] = current\n",
    "            # if neighbor not in open list, adding it\n",
    "            if neighbor not in open_list:\n",
    "                open_list.append(neighbor)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3256293b",
   "metadata": {},
   "source": [
    "####  Map with a single local minimum\n",
    "This map has a single local minimum; with a little backtracking we can handle this easily and in fact the character goes around the critical area and gets to the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b899217",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"MiniHack-Navigation-Custom-v0\",\n",
    "    observation_keys=(\"chars\", \"pixel\"),\n",
    "    des_file = \"mazes/medium_diff_maze.des\",\n",
    ")\n",
    "state = env.reset()\n",
    "\n",
    "plt.imshow(state['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a20fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = state['chars']\n",
    "game = state['pixel'][70:300, 500:730]\n",
    "\n",
    "start = get_player_location(game_map)\n",
    "target = get_target_location(game_map)\n",
    "print(\"Agent position:\", start)\n",
    "print(\"Target position:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfeb6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    path = hill_climb(game_map, start, target, manhattan_distance)\n",
    "    if path is not None:\n",
    "        print(\"Path found!\")\n",
    "    else:\n",
    "        print(\"Path not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1b99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = actions_from_path(start, path[1:])\n",
    "image = plt.imshow(game)\n",
    "for action in actions:\n",
    "    s, _, _, _ = env.step(action)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    image.set_data(s['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da5ffa7",
   "metadata": {},
   "source": [
    "####  A map with multiple local minima\n",
    "\n",
    "This map with several local minima tests the limit of this algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3634038d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Local Beam Search\n",
    "\n",
    "With this algorithm we trade off some memory for better exploration capabilities.\n",
    "\n",
    "The *k* best states are kept in memory and exploder when the current path being explored fails to reach the goal.\n",
    "\n",
    "This algorithm could be complete for maps of any size with the allocation of infinite memory, in theory.\n",
    "\n",
    "In practice, it's up to us to choose the best amount of memory to allocate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b37415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "def initialize_states(game_map: np.ndarray, start: Tuple[int, int], k: int):\n",
    "\n",
    "    init_states = [list(random.choice(get_valid_moves(game_map, start))) for _ in range(k)]\n",
    "    \n",
    "    current_states = []\n",
    "    for state in init_states:\n",
    "        current_states.append({\n",
    "            'current': tuple(state),\n",
    "            'explored_nodes': [tuple(state)],\n",
    "            'path': [tuple(state)]\n",
    "        })\n",
    "\n",
    "    return current_states\n",
    "\n",
    "def get_successors_from_states(game_map: np.ndarray, states: list):\n",
    "\n",
    "    state_neighbors = []\n",
    "\n",
    "    for state in states:\n",
    "        neighbors = get_valid_moves(game_map, state['current'])\n",
    "        state_neighbors.append({\n",
    "            'path': state['path'],\n",
    "            'explored_nodes': state['explored_nodes'],\n",
    "            'possible_moves': neighbors\n",
    "        })\n",
    "        \n",
    "\n",
    "    return state_neighbors\n",
    "\n",
    "def get_heuristic_scores(heuristic: callable, neighbors: list):\n",
    "\n",
    "    scored_moves = []\n",
    "\n",
    "    for state in neighbors:\n",
    "        for move in state['possible_moves']:\n",
    "            score_target = heuristic(move, target)\n",
    "            score_start = heuristic(start, move)\n",
    "            scored_moves.append({\n",
    "                'path': state['path'],\n",
    "                'explored_nodes': state['explored_nodes'],\n",
    "                'current': move,\n",
    "                'distance_from_target': score_target,\n",
    "                'distance_from_start': score_start\n",
    "            })\n",
    "    \n",
    "    return scored_moves\n",
    "\n",
    "def assign_probabilities(sorted_array):\n",
    "    n = len(sorted_array)\n",
    "    probabilities = [1 / (i + 1) for i in range(n)]\n",
    "    \n",
    "    # give the same probability if two elements has the same distance\n",
    "    for i in range(1, n):\n",
    "        if sorted_array[i] == sorted_array[i - 1]:\n",
    "            probabilities[i] = probabilities[i - 1]\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "def get_next_states(scored_successors: list, k: int, stocastic: bool):\n",
    "\n",
    "    scored_successors_from_target = sorted(scored_successors, key = lambda x: x['distance_from_target'])\n",
    "    scored_successors_from_start = sorted(scored_successors, key = lambda x: x['distance_from_start'], reverse=True)\n",
    "    scored_successors = None\n",
    "\n",
    "    if scored_successors_from_start[0]['distance_from_start'] - 15 < scored_successors_from_target[0]['distance_from_target'] :\n",
    "        scored_successors = scored_successors_from_start\n",
    "    else:\n",
    "        scored_successors = scored_successors_from_target\n",
    "\n",
    "    # scored_successors = scored_successors_from_start\n",
    "\n",
    "    top = []\n",
    "\n",
    "    if stocastic:\n",
    "        cont = 0\n",
    "        while cont < k:\n",
    "            # top.append(scored_successors[random.randrange(0, len(scored_successors))])\n",
    "            probability_array = assign_probabilities(scored_successors)\n",
    "            choice = random.choices(scored_successors, probability_array)[0]\n",
    "            if choice not in top:\n",
    "                top.append(choice)\n",
    "                cont += 1\n",
    "    else:\n",
    "        cont = 0\n",
    "        for succ in scored_successors:\n",
    "            if cont < k:\n",
    "                if succ['current'] not in succ['explored_nodes']:\n",
    "                    succ['explored_nodes'] = succ['explored_nodes'] + [succ['current']]\n",
    "                    top.append(succ)\n",
    "                    cont += 1\n",
    "\n",
    "                \n",
    "    \n",
    "    next_states = list()\n",
    "    \n",
    "    for s in top:\n",
    "        next_states.append({\n",
    "            'current': s['current'],\n",
    "            'explored_nodes': s['explored_nodes'],\n",
    "            'path': s['path'] + [s['current']]\n",
    "        })\n",
    "    \n",
    "    return next_states\n",
    "\n",
    "\n",
    "def local_beam_search(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int], heuristic: callable, k: int = 3, max_iter: int = 100, stocastic: bool = False):\n",
    "\n",
    "    current_states = initialize_states(game_map, start, k)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "\n",
    "        state_neighbors = get_successors_from_states(game_map, current_states)\n",
    "\n",
    "        if len(current_states) == 0 or i == max_iter - 1:\n",
    "            path = [start] + backup_states[0]['path'] + [move]\n",
    "            return None\n",
    "        \n",
    "        # check if a possible move is the target\n",
    "        for state in state_neighbors:\n",
    "            for move in state['possible_moves']:\n",
    "                if move == target:\n",
    "                   path = [start] + state['path'] + [move]\n",
    "                   return path\n",
    "\n",
    "        scored_successors = get_heuristic_scores(heuristic, state_neighbors)\n",
    "        backup_states = current_states\n",
    "        current_states = get_next_states(scored_successors, k, stocastic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491dbeef",
   "metadata": {},
   "source": [
    "#### Map with two local minima\n",
    "A map with two local minima, easy to manage for a beam search algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3500be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"MiniHack-Navigation-Custom-v0\",\n",
    "    observation_keys=(\"chars\", \"pixel\"),\n",
    "    des_file = \"mazes/two_local_minima.des\",\n",
    ")\n",
    "state = env.reset()\n",
    "\n",
    "plt.imshow(state['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef961c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = state['chars']\n",
    "game = state['pixel'][70:300, 500:730]\n",
    "start = get_player_location(game_map)\n",
    "target = get_target_location(game_map)\n",
    "print(\"Agent position:\", start)\n",
    "print(\"Target position:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ccf5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "founded = 0\n",
    "finalPath = None\n",
    "for i in range(1000):\n",
    "    path = local_beam_search(game_map, get_player_location(game_map), get_target_location(game_map), manhattan_distance, stocastic=False, max_iter=10000)\n",
    "    if path:\n",
    "        founded += 1\n",
    "        finalPath = path\n",
    "\n",
    "print(f\"{founded}/1000 correct paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af22c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = actions_from_path(start, path[1:])\n",
    "image = plt.imshow(game)\n",
    "for action in actions:\n",
    "    s, _, _, _ = env.step(action)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    image.set_data(s['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d625f5f",
   "metadata": {},
   "source": [
    "#### Medium difficulty maze\n",
    "A maze with multiple local minima, but still manageable for the Local Beam Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef52c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"MiniHack-Navigation-Custom-v0\",\n",
    "    observation_keys=(\"chars\", \"pixel\"),\n",
    "    des_file = \"mazes/low_diff_maze.des\",\n",
    ")\n",
    "state = env.reset()\n",
    "\n",
    "plt.imshow(state['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ef07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = state['chars']\n",
    "game = state['pixel'][70:300, 500:730]\n",
    "start = get_player_location(game_map)\n",
    "target = get_target_location(game_map)\n",
    "print(\"Agent position:\", start)\n",
    "print(\"Target position:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ff3b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_paths = 0\n",
    "finalPath = None\n",
    "for i in range(1000):\n",
    "    path = local_beam_search(game_map, get_player_location(game_map), get_target_location(game_map), manhattan_distance, stocastic=False, max_iter=10000)\n",
    "    if path is not None:\n",
    "        correct_paths += 1\n",
    "        finalPath = path\n",
    "\n",
    "print(f\"{correct_paths}/1000 correct paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = actions_from_path(start, finalPath[1:])\n",
    "image = plt.imshow(game)\n",
    "for action in actions:\n",
    "    s, _, _, _ = env.step(action)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    image.set_data(s['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c091b",
   "metadata": {},
   "source": [
    "#### Failure state map\n",
    "This is an example of a maze that can't be solved by the algorithm.\n",
    "\n",
    "We can see the player trying to get far away from the starting point and then getting stuck irreversably in a local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e8924",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"MiniHack-Navigation-Custom-v0\",\n",
    "    observation_keys=(\"chars\", \"pixel\"),\n",
    "    des_file = \"mazes/medium_diff_maze.des\",\n",
    ")\n",
    "state = env.reset()\n",
    "\n",
    "plt.imshow(state['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d6e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = state['chars']\n",
    "game = state['pixel'][70:300, 500:730]\n",
    "start = get_player_location(game_map)\n",
    "target = get_target_location(game_map)\n",
    "print(\"Agent position:\", start)\n",
    "print(\"Target position:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f28f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_paths = 0\n",
    "finalPath = None\n",
    "for i in range(1000):\n",
    "    path = local_beam_search(game_map, get_player_location(game_map), get_target_location(game_map), manhattan_distance, stocastic=False, max_iter=10000)\n",
    "    if path is not None:\n",
    "        correct_paths += 1\n",
    "        finalPath = path\n",
    "\n",
    "if correct_paths == 0:\n",
    "    print(\"No path to the exit has been found.\")\n",
    "else:\n",
    "    print(f\"{correct_paths}/1000 correct paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cef0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = actions_from_path(start, finalPath[1:])\n",
    "image = plt.imshow(game)\n",
    "for action in actions:\n",
    "    s, _, _, _ = env.step(action)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    image.set_data(s['pixel'][70:300, 500:730])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777c5d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Genetic Algorithm\n",
    "\n",
    "A custom genetic algorithm that can build path through evolutive concepts such as selection of best specimens in order to get better and better solutions, and mutation in order to explore good but unpromising paths."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
